{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import caiman as cm\n",
    "from caiman.utils.utils import download_demo\n",
    "from caiman.base.rois import extract_binary_masks_blob\n",
    "from caiman.utils.visualization import plot_contours, view_patches_bar\n",
    "from caiman.source_extraction.cnmf import cnmf as cnmf\n",
    "from caiman.motion_correction import MotionCorrect, tile_and_correct, motion_correction_piecewise \n",
    "from caiman.components_evaluation import estimate_components_quality, evaluate_components\n",
    "from caiman.tests.comparison import comparison\n",
    "\n",
    "from caiman.base.rois import com\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [{'fname': '/mnt/ceph/data/neuro/caiman/labeling/neurofinder.03.00.test/images/final_map/Yr_d1_498_d2_467_d3_1_order_C_frames_2250_.mmap', 'gSig': [8, 8]},\n",
    "          {'fname': '/mnt/ceph/data/neuro/caiman/labeling/neurofinder.04.00.test/images/final_map/Yr_d1_512_d2_512_d3_1_order_C_frames_3000_.mmap',\n",
    "              'gSig': [5, 5]},\n",
    "          {'fname': '/mnt/ceph/data/neuro/caiman/labeling/neurofinder.02.00/images/final_map/Yr_d1_512_d2_512_d3_1_order_C_frames_8000_.mmap',\n",
    "              'gSig': [5, 5]},\n",
    "          {'fname': '/mnt/ceph/data/neuro/caiman/labeling/yuste.Single_150u/images/final_map/Yr_d1_200_d2_256_d3_1_order_C_frames_3000_.mmap',\n",
    "              'gSig': [5, 5]},\n",
    "          {'fname': '/mnt/ceph/data/neuro/caiman/labeling/neurofinder.00.00/images/final_map/Yr_d1_512_d2_512_d3_1_order_C_frames_2936_.mmap',\n",
    "              'gSig': [6, 6]},\n",
    "          {'fname': '/mnt/ceph/data/neuro/caiman/labeling/neurofinder.01.01/images/final_map/Yr_d1_512_d2_512_d3_1_order_C_frames_1825_.mmap',\n",
    "              'gSig': [6, 6]},\n",
    "          {'fname': '/mnt/ceph/data/neuro/caiman/labeling/k53_20160530/images/final_map/Yr_d1_512_d2_512_d3_1_order_C_frames_116043_.mmap',\n",
    "              'gSig': [6, 6]},\n",
    "          {'fname': '/mnt/ceph/data/neuro/caiman/labeling/J115_2015-12-09_L01_ELS/images/final_map/Yr_d1_463_d2_472_d3_1_order_C_frames_90000_.mmap',\n",
    "              'gSig': [7, 7]},\n",
    "          {'fname': '/mnt/ceph/data/neuro/caiman/labeling/J123_2015-11-20_L01_0/images/final_map/Yr_d1_458_d2_477_d3_1_order_C_frames_41000_.mmap',\n",
    "              'gSig': [12, 12]},\n",
    "          {'fname': '/mnt/ceph/data/neuro/caiman/labeling/Jan-AMG_exp3_001/images/final_map/Yr_d1_512_d2_512_d3_1_order_C_frames_115897_.mmap',\n",
    "              'gSig': [7, 7]} ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dc in inputs[:]:\n",
    "    fname = dc['fname']\n",
    "    print(fname)\n",
    "    gSig = dc['gSig']\n",
    "    gt_file = os.path.join(os.path.split(fname)[0], os.path.split(fname)[\n",
    "                           1][:-4] + 'match_masks.npz')\n",
    "    # LOAD DATA\n",
    "    #analysis_file = '/mnt/ceph/neuro/jeremie_analysis/neurofinder.03.00.test/Yr_d1_498_d2_467_d3_1_order_C_frames_2250_._results_analysis.npz'\n",
    "    with np.load(os.path.join(os.path.split(fname)[0], os.path.split(fname)[1][:-4] + 'results_analysis.npz'), encoding='latin1') as ld:\n",
    "        print(ld.keys())\n",
    "        locals().update(ld)\n",
    "        dims_off = d1, d2\n",
    "        A = scipy.sparse.coo_matrix(A[()])\n",
    "        dims = (d1, d2)\n",
    "\n",
    "    gt_file = os.path.join(os.path.split(fname)[0], os.path.split(fname)[\n",
    "                           1][:-4] + 'match_masks.npz')\n",
    "    with np.load(gt_file, encoding='latin1') as ld:\n",
    "        print(ld.keys())\n",
    "        locals().update(ld)\n",
    "        A_gt = scipy.sparse.coo_matrix(A_gt[()])\n",
    "        dims = (d1, d2)\n",
    "\n",
    "    pl.figure()\n",
    "    dist_A = (normalize(A_gt.tocsc()[:, idx_components_gt], axis=0).T.dot(\n",
    "        normalize(A.tocsc()[:, :], axis=0))).toarray()\n",
    "    dist_C = normalize(C_gt[idx_components_gt], axis=1).dot(\n",
    "        normalize(C[:], axis=1).T)\n",
    "    dist_A = dist_A * (dist_A > 0)\n",
    "\n",
    "    pl.figure(figsize=(30, 20))\n",
    "    tp_gt, tp_comp, fn_gt, fp_comp, performance_cons_off = cm.base.rois.nf_match_neurons_in_binary_masks(A_gt.toarray()[:, idx_components_gt].reshape([dims[0], dims[1], -1], order='F').transpose([2, 0, 1]),\n",
    "                                                                                                         A.toarray()[:, :].reshape([dims[0], dims[1], -1], order='F').transpose([2, 0, 1]), thresh_cost=.7, min_dist=10,\n",
    "                                                                                                         print_assignment=False, plot_results=False, Cn=Cn, labels=['GT', 'Offline'], D=[1 - dist_A * (dist_C > .8)])\n",
    "    pl.rcParams['pdf.fonttype'] = 42\n",
    "    font = {'family': 'Myriad Pro',\n",
    "            'weight': 'regular',\n",
    "            'size': 20}\n",
    "    pl.rc('font', **font)\n",
    "    idx_final = tp_comp[np.where(dist_A[tp_gt, tp_comp] > 0.7)[0]]\n",
    "    np.savez(os.path.join(os.path.split(fname)[0], os.path.split(fname)[1][:-4] + '_training_set_minions.npz'), fname_new=fname,\n",
    "             A_seeded=A_gt.tocsc()[\n",
    "        :, idx_components_gt], C_seeded=C_gt[idx_components_gt], YrA_seeded=YrA_gt[idx_components_gt],\n",
    "        A_matched=A.tocsc()[\n",
    "        :, idx_final], C_matched=C[idx_final], YrA_matched=YrA[idx_final],\n",
    "        A_unmatched=A_gt.tocsc()[\n",
    "        :, fn_gt], C_unmatched=C_gt[fn_gt], YrA_unmatched=YrA_gt[fn_gt],\n",
    "        A_negative=A.tocsc()[\n",
    "        :, fp_comp], C_negative=C[fp_comp], YrA_negative=YrA[fp_comp],\n",
    "        r_values=r_values, fitness_delta=fitness_delta, fitness_raw=fitness_raw, Cn=Cn, dims=dims, gSig=gSig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_files = [os.path.join(dp, f) for dp, dn, filenames in os.walk('/mnt/ceph/data/neuro/caiman/') for f in filenames if 'set_minions.npz' in f]\n",
    "print(training_files)\n",
    "crop_size = 50\n",
    "half_crop = crop_size // 2\n",
    "from sklearn.preprocessing import normalize\n",
    "id_file = 0\n",
    "reference_gSig_neuron = 5\n",
    "#folder = '/mnt/xfs1/home/agiovann/SOFTWARE/CaImAn/images_examples'\n",
    "all_masks_gt = []\n",
    "labels_gt = []\n",
    "traces_gt = []\n",
    "for fl in training_files:\n",
    "\n",
    "    with np.load(fl) as ld:\n",
    "        print(ld.keys())\n",
    "        locals().update(ld)\n",
    "        zoom = reference_gSig_neuron / gSig[0]\n",
    "        fname_new = fname_new[()]\n",
    "        name_base = os.path.split(fname_new)[-1][:-5]\n",
    "#        pl.figure()\n",
    "#        pl.subplot(1, 3, 1)\n",
    "#        pl.imshow(A_matched[()].sum(1).reshape(dims,order='F'), vmax = A_matched[()].max()*.2)\n",
    "#        pl.subplot(1, 3, 2)\n",
    "#        pl.imshow(A_unmatched[()].sum(1).reshape(dims,order='F'), vmax = A_unmatched[()].max()*.2)\n",
    "#        pl.subplot(1, 3, 3)\n",
    "#        pl.imshow(A_negative[()].sum(1).reshape(dims,order='F'), vmax = A_negative[()].max()*.2)\n",
    "\n",
    "#        coms = com(scipy.sparse.coo_matrix(A_matched[()]), dims[0], dims[1])\n",
    "        if 'sparse' in str(type(A_matched[()])):\n",
    "            A_matched = A_matched[()].toarray()\n",
    "            A_unmatched = A_unmatched[()].toarray()\n",
    "            A_negative = A_negative[()].toarray()\n",
    "\n",
    "        A_matched = normalize(A_matched, axis=0)\n",
    "        A_unmatched = normalize(A_unmatched, axis=0)\n",
    "        A_negative = normalize(A_negative, axis=0)\n",
    "\n",
    "        masks_gt = np.concatenate([A_matched.reshape(tuple(dims) + (-1,), order='F').transpose([2, 0, 1]), A_unmatched.reshape(tuple(\n",
    "            dims) + (-1,), order='F').transpose([2, 0, 1]), A_negative.reshape(tuple(dims) + (-1,), order='F').transpose([2, 0, 1])], axis=0)\n",
    "        labels_gt = np.concatenate([labels_gt, np.ones(\n",
    "            A_matched.shape[-1]), np.ones(A_unmatched.shape[-1]), np.zeros(A_negative.shape[-1])])\n",
    "        traces_gt = traces_gt + list(YrA_matched + C_matched) + list(\n",
    "            C_unmatched + YrA_unmatched) + list(C_negative + YrA_negative)\n",
    "#        r_vals_gt = np.concatenate([r_vals_gt,])\n",
    "#        raw_fitness_gt = np.concatenate([raw_fitness_gt,])\n",
    "#        delta_fitness_gt = np.concatenate([delta_fitness_gt,])\n",
    "\n",
    "        coms = [scipy.ndimage.center_of_mass(mm) for mm in masks_gt]\n",
    "        coms = np.maximum(coms, half_crop)\n",
    "        coms = np.array([np.minimum(cm, dims - half_crop) for cm in coms])\n",
    "\n",
    "        count_neuro = 0\n",
    "        for com, img in zip(coms, masks_gt):\n",
    "            #            if zoom and zoom[counter]==1:\n",
    "            #            if zoom>1:\n",
    "            #\n",
    "            #            elif zoom<1:\n",
    "            com = com.astype(int)\n",
    "            # Crop from x, y, w, h -> 100, 200, 300, 400\n",
    "            crop_img = img[com[0] - half_crop:com[0] + half_crop,\n",
    "                           com[1] - half_crop:com[1] + half_crop].copy()\n",
    "#            crop_img = cv2.resize(crop_img,dsize=None,fx=zoom[id_file],fy=zoom[id_file])\n",
    "#            newshape = np.array(crop_img.shape)//2\n",
    "#            crop_img = crop_img[newshape[0]-half_crop:newshape[0]+half_crop,newshape[0]-half_crop:newshape[0]+half_crop]\n",
    "\n",
    "            borders = np.array(crop_img.shape)\n",
    "            img_tmp = np.zeros_like(crop_img)\n",
    "            crop_img = cv2.resize(crop_img, dsize=None, fx=zoom, fy=zoom)\n",
    "\n",
    "            deltaw = (half_crop * 2 - crop_img.shape[0]) // 2\n",
    "            deltah = (half_crop * 2 - crop_img.shape[1]) // 2\n",
    "            img_tmp[deltaw:deltaw + crop_img.shape[0],\n",
    "                    deltah:deltah + crop_img.shape[1]] = crop_img\n",
    "            crop_img = img_tmp\n",
    "            crop_img = crop_img / np.linalg.norm(crop_img)\n",
    "            all_masks_gt.append(crop_img[np.newaxis, :, :, np.newaxis])\n",
    "            augment_test = False\n",
    "            cv2.imshow(\"cropped\", cv2.resize(crop_img, (480, 480)) * 10)\n",
    "            cv2.waitKey(1)\n",
    "            if augment_test:\n",
    "                datagen = ImageDataGenerator(\n",
    "                    #            featurewise_center=True,\n",
    "                    #            featurewise_std_normalization=True,\n",
    "                    shear_range=0.3,\n",
    "                    rotation_range=360,\n",
    "                    width_shift_range=0.2,\n",
    "                    height_shift_range=0.2,\n",
    "                    zoom_range=[.5, 2],\n",
    "                    horizontal_flip=True,\n",
    "                    vertical_flip=True,\n",
    "                    random_mult_range=[.25, 2]\n",
    "                )\n",
    "\n",
    "                count_neuro += 1\n",
    "                for x_batch, y_batch in datagen.flow(np.repeat(crop_img[np.newaxis, :, :], 10, 0)[:, :, :, None], [1, 1, 1, 1, 1, 1, 1, 1, 0, 0], batch_size=10):\n",
    "                    print(y_batch)\n",
    "                    for b_img in x_batch:\n",
    "                        cv2.imshow(\"cropped\", cv2.resize(\n",
    "                            b_img.squeeze(), (480, 480)) * 10)\n",
    "                        cv2.waitKey(300)\n",
    "                        count_neuro += 1\n",
    "                        print(count_neuro)\n",
    "                    break\n",
    "\n",
    "\n",
    "#            crop_img = cv2.resize(crop_img,dsize=None,fx=2,fy=2)\n",
    "#            newshape = np.array(crop_img.shape)//2\n",
    "#            crop_img = crop_img[newshape[0]-half_crop:newshape[0]+half_crop,newshape[0]-half_crop:newshape[0]+half_crop]\n",
    "            # NOTE: its img[y: y + h, x: x + w] and *not* img[x: x + w, y: y + h]\n",
    "\n",
    "        id_file += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_masks_gt = np.vstack(all_masks_gt)\n",
    "#%%\n",
    "cm.movie(np.squeeze(all_masks_gt[labels_gt == 0])).play(\n",
    "    gain=3., magnification=10)\n",
    "#%%\n",
    "np.savez('ground_truth_components_minions.npz',\n",
    "         all_masks_gt=all_masks_gt, labels_gt=labels_gt, traces_gt=traces_gt)\n",
    "#%%\n",
    "import itertools\n",
    "\n",
    "\n",
    "def grouper(n, iterable, fillvalue=None):\n",
    "    \"grouper(3, 'ABCDEFG', 'x') --> ABC DEF Gxx\"\n",
    "    args = [iter(iterable)] * n\n",
    "    return itertools.zip_longest(*args, fillvalue=fillvalue)\n",
    "\n",
    "\n",
    "#%% curate once more. Remove wrong negatives\n",
    "negatives = np.where(labels_gt == 1)[0]\n",
    "wrong = []\n",
    "count = 0\n",
    "for a in grouper(50, negatives):\n",
    "    print(np.max(a))\n",
    "    print(count)\n",
    "    a = np.array(a)[np.array(a) > 0].astype(int)\n",
    "    count += 1\n",
    "    img_mont_ = all_masks_gt[np.array(a)].squeeze()\n",
    "    shps_img = img_mont_.shape\n",
    "    img_mont = montage2d(img_mont_)\n",
    "    shps_img_mont = np.array(img_mont.shape) // 50\n",
    "    pl.figure(figsize=(20, 30))\n",
    "    pl.imshow(img_mont)\n",
    "    inp = pl.ginput(n=0, timeout=-100000)\n",
    "    imgs_to_exclude = []\n",
    "    inp = np.ceil(np.array(inp) / 50).astype(int) - 1\n",
    "    if len(inp) > 0:\n",
    "\n",
    "        imgs_to_exclude = img_mont_[np.ravel_multi_index(\n",
    "            [inp[:, 1], inp[:, 0]], shps_img_mont)]\n",
    "#        pl.imshow(montage2d(imgs_to_exclude))\n",
    "        wrong.append(np.array(a)[np.ravel_multi_index(\n",
    "            [inp[:, 1], inp[:, 0]], shps_img_mont)])\n",
    "    np.save('temp_label_pos_minions.npy', wrong)\n",
    "    pl.close()\n",
    "#%%\n",
    "pl.imshow(montage2d(all_masks_gt[np.concatenate(wrong)].squeeze()))\n",
    "#%%\n",
    "lab_pos_wrong = np.load('temp_label_pos_minions.npy')\n",
    "lab_neg_wrong = np.load('temp_label_neg_plus_minions.npy')\n",
    "\n",
    "labels_gt_cur = labels_gt.copy()\n",
    "labels_gt_cur[np.concatenate(lab_pos_wrong)] = 0\n",
    "labels_gt_cur[np.concatenate(lab_neg_wrong)] = 1\n",
    "\n",
    "np.savez('ground_truth_comoponents_curated_minions.npz',\n",
    "         all_masks_gt=all_masks_gt, labels_gt_cur=labels_gt_cur)\n",
    "#%%\n",
    "pl.imshow(montage2d(all_masks_gt[labels_gt_cur == 0].squeeze()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "caiman_pytorch",
   "language": "python",
   "name": "caiman_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
